{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-14 22:52:44,944 - __main__ - INFO - Starting the application...\n",
      "2025-05-14 22:52:44,947 - config.config - INFO - Attempting to load configuration from config.json\n",
      "2025-05-14 22:52:44,950 - config.config - INFO - Configuration loaded successfully.\n",
      "2025-05-14 22:52:44,955 - config.config - INFO - Configuration validated.\n"
     ]
    }
   ],
   "source": [
    "from config.utils import setup_logging, get_logger\n",
    "from config.config import ConfigManager\n",
    "\n",
    "setup_logging(level=\"INFO\")\n",
    "logger = get_logger(__name__)\n",
    "logger.info(\"Starting the application...\")\n",
    "config = ConfigManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection\n",
    "\n",
    "**fetches the data from the sources identified in config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-14 22:53:08,818 - data_collection.collect_data - INFO - Loading configuration...\n",
      "2025-05-14 22:53:08,820 - config.config - INFO - Attempting to load configuration from config.json\n",
      "2025-05-14 22:53:08,822 - config.config - INFO - Configuration loaded successfully.\n",
      "2025-05-14 22:53:08,823 - config.config - INFO - Configuration validated.\n",
      "2025-05-14 22:53:08,823 - data_collection.collect_data - INFO - Configuration loaded. Log file set to: documentation.log\n",
      "2025-05-14 22:53:08,824 - data_collection.collect_data - INFO - Initialization complete. Starting data fetch.\n",
      "2025-05-14 22:53:08,825 - data_collection.fetcher - INFO - Documentation storage path: /Users/eliza/search-pydantic-ai/retrieved_data/documentation_raw\n",
      "2025-05-14 22:53:08,826 - data_collection.collect_data - INFO - Fetching 1 documentation sources\n",
      "2025-05-14 22:53:08,826 - data_collection.fetcher - INFO - Starting documentation fetch process for 1 URLs...\n",
      "2025-05-14 22:53:08,827 - data_collection.fetcher - INFO - Attempting to fetch documentation from: https://ai.pydantic.dev/ (max_depth=5)\n",
      "2025-05-14 22:54:39,196 - langchain_community.document_loaders.recursive_url_loader - WARNING - Unable to load from https://ai.pydantic.dev/. Received error HTTPSConnectionPool(host='ai.pydantic.dev', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x109c38530>, 'Connection to ai.pydantic.dev timed out. (connect timeout=30)')) of type ConnectTimeout\n",
      "2025-05-14 22:54:39,198 - data_collection.fetcher - INFO - Successfully fetched 0 documents from https://ai.pydantic.dev/\n",
      "2025-05-14 22:54:39,200 - data_collection.fetcher - INFO - Attempted to save content of 0 documents to /Users/eliza/search-pydantic-ai/retrieved_data/documentation_raw/ai.pydantic.dev_index, successfully saved: 0\n",
      "2025-05-14 22:54:39,201 - data_collection.fetcher - INFO - Documentation fetch process finished. Fetched from 1 URLs, failed for 0.\n",
      "2025-05-14 22:54:39,202 - data_collection.collect_data - INFO - Documentation fetch process finished (placeholder).\n",
      "2025-05-14 22:54:39,204 - data_collection.collect_data - INFO - Initial data collection finished in 90.38 seconds.\n"
     ]
    }
   ],
   "source": [
    "from data_collection.collect_data import run_initial_fetch\n",
    "\n",
    "run_initial_fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking and vectorization\n",
    "\n",
    "**updates the vector db incrementally**\n",
    "\n",
    "OpenAI or HF embeddings can be chosen in config.json.\n",
    "Defaults to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-14 22:54:39,422 - vectorizing_and_retrieval.create_vectors - INFO - Processing 1 unique documentation URLs from config.\n",
      "2025-05-14 22:54:39,423 - vectorizing_and_retrieval.create_vectors - INFO - Starting vector DB update for URL: https://ai.pydantic.dev/\n",
      "2025-05-14 22:54:39,424 - vectorizing_and_retrieval.create_vectors - INFO - Vector store index path: /Users/eliza/search-pydantic-ai/retrieved_data/vector_store/ai_pydantic_dev_index\n",
      "2025-05-14 22:54:40,746 - vectorizing_and_retrieval.create_vectors - INFO - Initializing OpenAI Embeddings (Model: text-embedding-3-small)\n",
      "2025-05-14 22:54:40,817 - vectorizing_and_retrieval.create_vectors - INFO - Attempting to load existing vector store from: /Users/eliza/search-pydantic-ai/retrieved_data/vector_store/ai_pydantic_dev_index\n",
      "2025-05-14 22:54:40,821 - faiss.loader - INFO - Loading faiss with AVX512 support.\n",
      "2025-05-14 22:54:40,822 - faiss.loader - INFO - Could not load library with AVX512 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx512'\")\n",
      "2025-05-14 22:54:40,822 - faiss.loader - INFO - Loading faiss with AVX2 support.\n",
      "2025-05-14 22:54:40,850 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n",
      "2025-05-14 22:54:40,859 - faiss - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n",
      "2025-05-14 22:54:40,869 - vectorizing_and_retrieval.create_vectors - INFO - Initializing OpenAI Embeddings (Model: text-embedding-3-small)\n",
      "2025-05-14 22:54:40,894 - vectorizing_and_retrieval.create_vectors - INFO - Loaded existing vector store from /Users/eliza/search-pydantic-ai/retrieved_data/vector_store/ai_pydantic_dev_index\n",
      "2025-05-14 22:54:40,895 - vectorizing_and_retrieval.create_vectors - INFO - Processing files in source directory: /Users/eliza/search-pydantic-ai/retrieved_data/documentation_raw/ai.pydantic.dev_index\n",
      "2025-05-14 22:54:40,898 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: stream-markdown.json\n",
      "2025-05-14 22:54:40,899 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: dependencies.json\n",
      "2025-05-14 22:54:40,901 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: function.json\n",
      "2025-05-14 22:54:40,902 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: evaluators.json\n",
      "2025-05-14 22:54:40,904 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: pydantic-model.json\n",
      "2025-05-14 22:54:40,905 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: usage.json\n",
      "2025-05-14 22:54:40,906 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: testing.json\n",
      "2025-05-14 22:54:40,908 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: anthropic.json\n",
      "2025-05-14 22:54:40,909 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: common_tools.json\n",
      "2025-05-14 22:54:40,910 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: models.json\n",
      "2025-05-14 22:54:40,912 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: openai.json\n",
      "2025-05-14 22:54:40,913 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: common-tools.json\n",
      "2025-05-14 22:54:40,914 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: result.json\n",
      "2025-05-14 22:54:40,915 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: settings.json\n",
      "2025-05-14 22:54:40,916 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: run-python.json\n",
      "2025-05-14 22:54:40,917 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: weather-agent.json\n",
      "2025-05-14 22:54:40,919 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: server.json\n",
      "2025-05-14 22:54:40,920 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: instrumented.json\n",
      "2025-05-14 22:54:40,922 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: sql-gen.json\n",
      "2025-05-14 22:54:40,923 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: contributing.json\n",
      "2025-05-14 22:54:40,924 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: examples.json\n",
      "2025-05-14 22:54:40,925 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: troubleshooting.json\n",
      "2025-05-14 22:54:40,927 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: input.json\n",
      "2025-05-14 22:54:40,929 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: fasta2a.json\n",
      "2025-05-14 22:54:40,930 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: tools.json\n",
      "2025-05-14 22:54:40,932 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: mermaid.json\n",
      "2025-05-14 22:54:40,933 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: flight-booking.json\n",
      "2025-05-14 22:54:40,934 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: fallback.json\n",
      "2025-05-14 22:54:40,936 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: providers.json\n",
      "2025-05-14 22:54:40,937 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: messages.json\n",
      "2025-05-14 22:54:40,939 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: output.json\n",
      "2025-05-14 22:54:40,940 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: evals.json\n",
      "2025-05-14 22:54:40,942 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: agents.json\n",
      "2025-05-14 22:54:40,944 - vectorizing_and_retrieval.create_vectors - INFO - Generated 13 chunks for file: agent.json\n",
      "2025-05-14 22:54:40,946 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: mistral.json\n",
      "2025-05-14 22:54:40,947 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: test.json\n",
      "2025-05-14 22:54:40,948 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: cli.json\n",
      "2025-05-14 22:54:40,949 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: message-history.json\n",
      "2025-05-14 22:54:40,950 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: exceptions.json\n",
      "2025-05-14 22:54:40,952 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: direct.json\n",
      "2025-05-14 22:54:40,953 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: logfire.json\n",
      "2025-05-14 22:54:40,954 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: cohere.json\n",
      "2025-05-14 22:54:40,955 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: a2a.json\n",
      "2025-05-14 22:54:40,957 - vectorizing_and_retrieval.create_vectors - INFO - Processing markdown file: llms-fulltxt.json\n",
      "2025-05-14 22:54:40,987 - vectorizing_and_retrieval.create_vectors - INFO - Generated 195 chunks for file: llms-fulltxt.json\n",
      "2025-05-14 22:54:40,990 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: otel.json\n",
      "2025-05-14 22:54:40,992 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: bank-support.json\n",
      "2025-05-14 22:54:40,994 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: gemini.json\n",
      "2025-05-14 22:54:40,995 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: groq.json\n",
      "2025-05-14 22:54:40,997 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: graph.json\n",
      "2025-05-14 22:54:40,998 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: page_0.json\n",
      "2025-05-14 22:54:41,000 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: reporting.json\n",
      "2025-05-14 22:54:41,001 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: generation.json\n",
      "2025-05-14 22:54:41,003 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: base.json\n",
      "2025-05-14 22:54:41,004 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: changelog.json\n",
      "2025-05-14 22:54:41,005 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: help.json\n",
      "2025-05-14 22:54:41,007 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: multi-agent-applications.json\n",
      "2025-05-14 22:54:41,008 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: wrapper.json\n",
      "2025-05-14 22:54:41,010 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: bedrock.json\n",
      "2025-05-14 22:54:41,011 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: stream-whales.json\n",
      "2025-05-14 22:54:41,013 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: client.json\n",
      "2025-05-14 22:54:41,014 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: rag.json\n",
      "2025-05-14 22:54:41,015 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: llmstxt.json\n",
      "2025-05-14 22:54:41,017 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: question-graph.json\n",
      "2025-05-14 22:54:41,018 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: format_as_xml.json\n",
      "2025-05-14 22:54:41,020 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: nodes.json\n",
      "2025-05-14 22:54:41,021 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: install.json\n",
      "2025-05-14 22:54:41,022 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: mcp.json\n",
      "2025-05-14 22:54:41,023 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: persistence.json\n",
      "2025-05-14 22:54:41,024 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: dataset.json\n",
      "2025-05-14 22:54:41,026 - vectorizing_and_retrieval.create_vectors - INFO - Generated 1 chunks for file: chat-app.json\n",
      "2025-05-14 22:54:41,027 - vectorizing_and_retrieval.create_vectors - INFO - Finished processing files for URL: https://ai.pydantic.dev/. Found sources: ['https://ai.pydantic.dev/models/mistral/', 'https://ai.pydantic.dev/api/pydantic_evals/generation/', 'https://ai.pydantic.dev/api/models/wrapper/', 'https://ai.pydantic.dev/api/models/fallback/', 'https://ai.pydantic.dev/api/pydantic_evals/otel/', 'https://ai.pydantic.dev/api/models/function/', 'https://ai.pydantic.dev/api/result/', 'https://ai.pydantic.dev/models/bedrock/', 'https://ai.pydantic.dev/mcp/run-python/', 'https://ai.pydantic.dev/examples/stream-whales/', 'https://ai.pydantic.dev/examples/pydantic-model/', 'https://ai.pydantic.dev/api/format_as_xml/', 'https://ai.pydantic.dev/api/usage/', 'https://ai.pydantic.dev/output/', 'https://ai.pydantic.dev/examples/bank-support/', 'https://ai.pydantic.dev/examples/stream-markdown/', 'https://ai.pydantic.dev/llms.txt', 'https://ai.pydantic.dev/api/pydantic_graph/nodes/', 'https://ai.pydantic.dev/examples/weather-agent/', 'https://ai.pydantic.dev/mcp/client/', 'https://ai.pydantic.dev/examples/rag/', 'https://ai.pydantic.dev/examples/question-graph/', 'https://ai.pydantic.dev/api/pydantic_evals/dataset/', 'https://ai.pydantic.dev/api/fasta2a/', 'https://ai.pydantic.dev/logfire/', 'https://ai.pydantic.dev/api/pydantic_graph/graph/', 'https://ai.pydantic.dev/api/messages/', 'https://ai.pydantic.dev/direct/', 'https://ai.pydantic.dev/changelog/', 'https://ai.pydantic.dev/examples/chat-app/', 'https://ai.pydantic.dev/contributing/', 'https://ai.pydantic.dev/examples/', 'https://ai.pydantic.dev/models/', 'https://ai.pydantic.dev/testing/', 'https://ai.pydantic.dev/examples/sql-gen/', 'https://ai.pydantic.dev/troubleshooting/', 'https://ai.pydantic.dev/mcp/server/', 'https://ai.pydantic.dev/api/pydantic_graph/mermaid/', 'https://ai.pydantic.dev/examples/flight-booking/', 'https://ai.pydantic.dev/agents/', 'https://ai.pydantic.dev/tools/', 'https://ai.pydantic.dev/multi-agent-applications/', 'https://ai.pydantic.dev/evals/', 'https://ai.pydantic.dev/api/models/base/', 'https://ai.pydantic.dev/api/settings/', 'https://ai.pydantic.dev/api/models/test/', 'https://ai.pydantic.dev/message-history/', 'https://ai.pydantic.dev/api/common_tools/', 'https://ai.pydantic.dev/cli/', 'https://ai.pydantic.dev/models/cohere/', 'https://ai.pydantic.dev/dependencies/', 'https://ai.pydantic.dev/common-tools/', 'https://ai.pydantic.dev/api/providers/', 'https://ai.pydantic.dev/install/', 'https://ai.pydantic.dev/api/pydantic_evals/reporting/', 'https://ai.pydantic.dev/mcp/', 'https://ai.pydantic.dev/models/gemini/', 'https://ai.pydantic.dev/api/models/groq/', 'https://ai.pydantic.dev/api/exceptions/', 'https://ai.pydantic.dev/api/pydantic_graph/persistence/', 'https://ai.pydantic.dev/api/pydantic_evals/evaluators/', 'https://ai.pydantic.dev/help/', 'https://ai.pydantic.dev/models/openai/', 'https://ai.pydantic.dev/input/', 'https://ai.pydantic.dev/llms-full.txt', 'https://ai.pydantic.dev/', 'https://ai.pydantic.dev/api/models/instrumented/', 'https://ai.pydantic.dev/models/anthropic/', 'https://ai.pydantic.dev/a2a/', 'https://ai.pydantic.dev/api/agent/']\n",
      "2025-05-14 22:54:41,028 - vectorizing_and_retrieval.create_vectors - INFO - No stale sources found to delete.\n",
      "2025-05-14 22:54:41,028 - vectorizing_and_retrieval.create_vectors - INFO - Update complete for https://ai.pydantic.dev/. Updated chunks: 0, Deleted stale chunks: 0\n",
      "2025-05-14 22:54:41,029 - vectorizing_and_retrieval.create_vectors - INFO - Finished processing all URLs.\n",
      "2025-05-14 22:54:41,030 - vectorizing_and_retrieval.create_vectors - INFO - Total chunks updated (added/replaced): 0\n",
      "2025-05-14 22:54:41,030 - vectorizing_and_retrieval.create_vectors - INFO - Total stale chunks deleted: 0\n"
     ]
    }
   ],
   "source": [
    "from vectorizing_and_retrieval.create_vectors import (\n",
    "    update_vector_db_for_all_urls,\n",
    ")\n",
    "update_vector_db_for_all_urls(config.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a simple graph overlay\n",
    "\n",
    "Just to connect nearby chunks. But I hope to connect documents also based on symbols used and potentially connect them to source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-14 22:54:41,337 - vectorizing_and_retrieval.create_graphs - INFO - Processing 1 unique documentation URLs for graph creation.\n",
      "2025-05-14 22:54:41,338 - vectorizing_and_retrieval.create_graphs - INFO - Processing files in source directory: /Users/eliza/search-pydantic-ai/retrieved_data/documentation_raw/ai.pydantic.dev_index\n",
      "2025-05-14 22:54:41,339 - vectorizing_and_retrieval.create_vectors - INFO - Initializing OpenAI Embeddings (Model: text-embedding-3-small)\n",
      "2025-05-14 22:54:41,363 - vectorizing_and_retrieval.create_vectors - INFO - Attempting to load existing vector store from: /Users/eliza/search-pydantic-ai/retrieved_data/vector_store/ai_pydantic_dev_index\n",
      "Total edges created: 37986\n",
      "Total edges created: 37986\n",
      "2025-05-14 22:54:41,595 - vectorizing_and_retrieval.create_graphs - INFO - Serializing graph with 276 nodes and 37986 edges to /Users/eliza/search-pydantic-ai/retrieved_data/graphs/ai_pydantic_dev_index.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eliza/search-pydantic-ai/venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/node_link.py:142: FutureWarning: \n",
      "The default value will be `edges=\"edges\" in NetworkX 3.6.\n",
      "\n",
      "To make this warning go away, explicitly set the edges kwarg, e.g.:\n",
      "\n",
      "  nx.node_link_data(G, edges=\"links\") to preserve current behavior, or\n",
      "  nx.node_link_data(G, edges=\"edges\") for forward compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from vectorizing_and_retrieval.create_graphs import create_graph_for_all_urls\n",
    "\n",
    "create_graph_for_all_urls(config.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
